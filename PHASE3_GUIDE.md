# Phase 3 Quick Reference Guide

## âœ… Phase 3 Implementation Complete

All required files for Phase 3 have been created:

### New Files Created
- âœ… `client/fl_client.py` - Flower client implementation
- âœ… `server/server.py` - Federated server with FedAvg
- âœ… `phase3_main.py` - Main execution script
- âœ… `requirements.txt` - Updated with Flower

### Updated Files
- âœ… `README.md` - Added Phase 3 documentation

---

## ğŸ¤ Federated Learning Overview

**What is Federated Learning?**
- Multiple clients (hospitals) collaborate to train a model
- Raw data NEVER leaves clients
- Only model weights are shared
- Server aggregates weights using FedAvg

**Key Privacy Feature:**
- Model weights are just numbers (no patient data)
- Raw data stays local at each client
- HIPAA/GDPR compliant

---

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Ensure Phases 1 & 2 are Complete
- Client datasets should exist in `dataset/processed/`
- If not, run: `python phase1_main.py`

### 3. Run Phase 3
```bash
python phase3_main.py
```

This will:
- Start federated learning server
- Start 3 clients (simulated on same machine)
- Run 10 federated rounds
- Aggregate model weights using FedAvg
- Train global federated model

---

## ğŸ“‹ Alternative: Run Separately

### Terminal 1 - Server
```bash
python server/server.py --rounds 10 --epochs 5
```

### Terminal 2 - Client 1
```python
from client.fl_client import create_flower_client
import flwr as fl

client = create_flower_client(
    client_id=1,
    client_data_path="dataset/processed/client_1.csv",
    num_features=13
)
fl.client.start_numpy_client("localhost:8080", client)
```

### Terminal 3 - Client 2
```python
from client.fl_client import create_flower_client
import flwr as fl

client = create_flower_client(
    client_id=2,
    client_data_path="dataset/processed/client_2.csv",
    num_features=13
)
fl.client.start_numpy_client("localhost:8080", client)
```

### Terminal 4 - Client 3
```python
from client.fl_client import create_flower_client
import flwr as fl

client = create_flower_client(
    client_id=3,
    client_data_path="dataset/processed/client_3.csv",
    num_features=13
)
fl.client.start_numpy_client("localhost:8080", client)
```

---

## ğŸ”„ Federated Learning Process

1. **Server Initializes**: Creates global model
2. **Clients Connect**: Each client connects to server
3. **Model Distribution**: Server sends global weights to clients
4. **Local Training**: Each client trains on private data
5. **Weight Collection**: Clients send updated weights (NOT data)
6. **Aggregation**: Server aggregates using FedAvg
7. **Distribution**: Server sends aggregated model to clients
8. **Repeat**: Steps 3-7 for multiple rounds

---

## ğŸ“Š FedAvg Algorithm

**Federated Averaging Formula:**
```
w_global = Î£(n_i * w_i) / Î£(n_i)
```

Where:
- `w_global` = aggregated global weights
- `n_i` = number of samples at client i
- `w_i` = weights from client i

**Why Weighted Average?**
- Clients with more data have more influence
- Ensures fair aggregation
- Better global model performance

---

## ğŸ”’ Privacy Explanation

### Why Only Weights Are Shared?

**Model Weights:**
- Just numbers representing learned patterns
- Example: [0.234, -0.567, 0.891, ...]
- Contains NO patient information
- Cannot be reverse-engineered to get raw data

**Raw Data:**
- Contains sensitive patient information
- Example: "Patient 123: Age=65, Cholesterol=250"
- Must stay local for privacy

**Result:**
- Privacy preserved (HIPAA/GDPR compliant)
- Model learns from all clients' data
- No data breach risk

---

## ğŸ“ Viva Points

### Why Federated Learning?

1. **Privacy**: Raw data never leaves clients
2. **Security**: No single point of failure
3. **Scalability**: Works with distributed data
4. **Efficiency**: Local training reduces network traffic
5. **Collaboration**: Multiple hospitals can work together

### FedAvg Algorithm

1. **Weighted Average**: Clients with more data have more influence
2. **Iterative Process**: Multiple rounds improve global model
3. **Convergence**: Model improves with each round
4. **Fair Aggregation**: All clients contribute proportionally

### Privacy Preservation

1. **No Data Sharing**: Only weights, never raw data
2. **Local Processing**: All training happens at clients
3. **Secure Communication**: Only model parameters transmitted
4. **Compliance**: Meets HIPAA/GDPR requirements

---

## ğŸ“ File Structure

```
client/
â””â”€â”€ fl_client.py          # Flower client

server/
â””â”€â”€ server.py             # Federated server

phase3_main.py            # Main execution script
```

---

## ğŸ”§ Configuration

Default federated learning parameters:
- **Rounds**: 10
- **Local Epochs**: 5 per round
- **Learning Rate**: 0.001
- **Server Address**: localhost:8080
- **Clients**: 3

Modify in `phase3_main.py` or pass as arguments.

---

## â“ Troubleshooting

**Issue**: Clients can't connect to server
- **Solution**: Start server first, wait 5 seconds, then start clients

**Issue**: Port already in use
- **Solution**: Change port in `server/server.py --address localhost:8081`

**Issue**: Import errors
- **Solution**: Install Flower: `pip install flwr`

**Issue**: Client data not found
- **Solution**: Run Phase 1 first: `python phase1_main.py`

---

## ğŸ“ˆ Expected Output

### Server Output
```
FEDERATED LEARNING SERVER - PHASE 3
============================================================
Server Address: localhost:8080
Number of Rounds: 10
Local Epochs per Round: 5
Learning Rate: 0.001
============================================================

Starting server on localhost:8080...
Waiting for clients to connect...
```

### Client Output
```
[Client 1] Loading local dataset...
[Client 1] Local data prepared:
[Client 1]   Train samples: 268
[Client 1]   Test samples: 67
[Client 1] Flower client initialized
[Client 1] Connecting to server at localhost:8080...
[Client 1] Training locally for 5 epochs...
[Client 1] Evaluation - Loss: 0.3456, Accuracy: 0.8500
```

---

## ğŸ‰ Project Complete!

All three phases are now complete:
- âœ… Phase 1: Dataset Engineering & Preprocessing
- âœ… Phase 2: Deep Learning Model & Local Training
- âœ… Phase 3: Federated Learning

**The complete federated learning system is ready!**

---

**Phase 3 Complete! Full Federated Learning System Implemented!**

